---
title: "2024 하반기 회고. part 2"
date: 2024-12-14 12:19:00 +0900
categories: personal postmortem
---

앞글에 이어서 진행합니다.
[2024 하반기 회고. part 1](https://kimohy.github.io/personal/postmortem/2024-%ED%95%98%EB%B0%98%EA%B8%B0-%ED%9A%8C%EA%B3%A0-Part-1/)


# Insight Generation

우여곡절 끝에 생성형 AI 를 기반으로 한 데이터 분석 서비스를 런칭하게 됩니다.
특히 우리 파트가 맡은 역할은 주어진 데이터 테이블을 기반으로 인사이트를 생성하는 역할입니다.

생성형 기반의 서비스에서 데이터의 인사이트는 어떻게 정의할 수 있을까요.

예를들어 *2024년 8월의 a제품의 판매량을 알려줘* 라고 질문 했을 때,

1. *판매량* 을 찾을 수 있는 데이터 소스를 알아야 하고 (table search)
2. *A제품* 이 무엇인지 (model name) 를 알아야 하고 (filtering)
3. *2024년 8월* 을 판매시간 정보로 추출하고 (filtering)
4. 그 합계를 연산합니다. (sum)

이 요구사항은 SQL 을 생성하고 실행하는 것으로 데이터를 확인 할 수 있습니다. (Text-to-SQL)

그런데 인사이트라면 무엇일까요?

8월의 제품 판매량으로는 이해할 수 있는 내용이 부족합니다. 

- 7월에 비해서 얼마나 달라졌는지
- 혹은 작년에 비해서 얼마나 달라졌는지.
- 여름 마케팅과 연관성이 있는지
- 다른 제품군과 다른 특징이 있는지
- 외부에서 어떠한 이슈가 있는지 (뉴스/SNS)
- 9월의 판매량은 어떻게 예상 되는지
- ...

특징, 특이점을 찾는 것에는 이러한 요소가 있다고 볼 수 있습니다.
어떻게 보면 데이터 과학자, 분석가가 하는 일이라고 할 수도 있고, 상당히 복잡하고 어려운 일입니다.

그런데 더 큰 문제는, 꽤 많은 문제에서 **정답이 없습니다**

정답이 없는 문제는 인공지능을 사용하는데 있어서 상당히 어렵습니다.
전통적인 머신러닝부터 LLM 까지 학습의 기본이 되는 것은 정답과의 오차를 최소화 시키는 방향입니다.
그런데 정답이라는 것이 모호하고 애매하다면 학습이라는 개념이 성립되지 않습니다.

# 정답이 없다면 정답에 가깝도록

그래도 다행인 부분은 LLM 이 상당히 지능적이라는 것 입니다.
스스로 생각 하는 것처럼 보여지고 나름 합리적인 판단을 합니다.

그렇다면 *정량적인 정답이 아니더라도 정성적인 내용을 정량화 시키는 것이 가능* 합니다.

즉, 인사이트 결과가 정답인지 아닌지는 판단하기 어렵지만
(다음달에 무슨일이 일어날지 어떻게 알겠습니까?!)

정답을 추론하는 과정이나 계산식의 생성이 적합한지를 판단시킬 수 있습니다.
게다가 LLM의 발전에 따라 더욱더 정교해지고 있습니다.

# 환각 전쟁

LLM 의 Hallucination (환각) 은 극복하기 어려운 주제입니다. 
확률분포를 기반으로 하는 모델의 특성상 가능성은 언제나 존재하기 때문입니다.

특히나 데이터, 숫자를 다루는 이 도메인에서는 환각은 아주 치명적입니다.
데이터 의사결정을 하는데 있어 수치를 틀린다는 것은 치명적인 실수를 할 수 있기 때문입니다. 

LLM 기반 서비스를 개발하면서 환각과 관련해 느낀 몇가지가 있었습니다.

1. LLM 에게 특이한 짓을 시키지 말자.

기본적인 LLM 모델은 일반적인 지식 (상식) 으로 학습되어 있습니다. 
학습되지 않았을 법한 흔하지 않은 지시사항과 요구사항은 LLM 을 당황 시킵니다. 
즉 실수할 가능성이 높아집니다.

2. LLM 의 실수는 시스템적으로 해결하자.

LLM 에게 숫자 덧셈을 시키면 쉬운 것임에도 불구하고 틀리는 경우가 많았습니다. 
(물론 최근에 모델들은 그마저도 잘 하는 경향이 있습니다.)

그렇기 때문에 중요한 계산과 연산은 프로그래밍 코드를 생성시켜서 실행하도록 합니다. (function call)

또한 prompt hacking 을 하게되면 사용자가 LLM 에게 이상한 짓을 하도록 시킬 수 도 있습니다.
사전에 원천 차단을 하게하기 위해서는 시스템적으로 권한을 제한하도록 해야 합니다.
(AGI 시대가 되면 세상을 혼란시키게 할 수도 있겠죠?)

3. 말이 많아지면 실언할 가능성도 높아진다.

이건 사람에게도 통용되는 말이지만 LLM 도 마찬가지 입니다. 
데이터를 설명하는데 있어 말이 길어지면 환각현상이 나타날 가능성도 높습니다. 
그 이유는 학습 데이터에 비슷한 내용을 설명하기 때문이라고 봅니다.

예를들어 스마트폰의 판매량에 대한 내용은 뉴스 기사나 블로그글 등을 통해 학습이 많이 되었을 것 입니다.
따라서 작년의 스마트폰 판매량을 답변하다 보면 학습된 내용이 슬쩍 나오기도 합니다.

# 정리

글을 쓰다보니 기술적 내용에 조금 더 포커스가 되었네요.
여튼 서비스는 런칭하였고 운영중에 있습니다. 
임직원들이 쉽고 빠르게 데이터 분석을 할 수 있는 환경을 제공합니다.

우리 파트에서 하지 않는 일도 다양하고 LLM 서비스를 위한 큰 주제들 입니다. 
하나씩 열거하며 정리하면 좋겠지만 너무 방대하네요.

하반기 회고는 다음 part 3 에서 이어져야겠습니다.
부디 올해가 끝나기 전에 마무리 할 수 있으면 좋겠습니다.
